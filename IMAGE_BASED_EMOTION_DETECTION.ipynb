{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n",
      "Epoch 1/50\n",
      "897/897 [==============================] - 297s 329ms/step - loss: 1.7550 - accuracy: 0.2841 - val_loss: 1.6593 - val_accuracy: 0.3810\n",
      "Epoch 2/50\n",
      "897/897 [==============================] - 49s 54ms/step - loss: 1.6230 - accuracy: 0.3651 - val_loss: 1.4950 - val_accuracy: 0.4268\n",
      "Epoch 3/50\n",
      "897/897 [==============================] - 48s 53ms/step - loss: 1.5552 - accuracy: 0.3980 - val_loss: 1.3998 - val_accuracy: 0.4541\n",
      "Epoch 4/50\n",
      "897/897 [==============================] - 51s 56ms/step - loss: 1.5062 - accuracy: 0.4172 - val_loss: 1.3531 - val_accuracy: 0.4782\n",
      "Epoch 5/50\n",
      "897/897 [==============================] - 52s 58ms/step - loss: 1.4792 - accuracy: 0.4267 - val_loss: 1.3354 - val_accuracy: 0.4911\n",
      "Epoch 6/50\n",
      "897/897 [==============================] - 52s 58ms/step - loss: 1.4569 - accuracy: 0.4405 - val_loss: 1.3326 - val_accuracy: 0.4933\n",
      "Epoch 7/50\n",
      "897/897 [==============================] - 51s 57ms/step - loss: 1.4383 - accuracy: 0.4448 - val_loss: 1.3074 - val_accuracy: 0.5067\n",
      "Epoch 8/50\n",
      "897/897 [==============================] - 51s 57ms/step - loss: 1.4252 - accuracy: 0.4512 - val_loss: 1.2837 - val_accuracy: 0.5078\n",
      "Epoch 9/50\n",
      "897/897 [==============================] - 54s 61ms/step - loss: 1.4117 - accuracy: 0.4574 - val_loss: 1.3034 - val_accuracy: 0.5092\n",
      "Epoch 10/50\n",
      "897/897 [==============================] - 50s 55ms/step - loss: 1.4003 - accuracy: 0.4627 - val_loss: 1.2786 - val_accuracy: 0.5153\n",
      "Epoch 11/50\n",
      "897/897 [==============================] - 49s 54ms/step - loss: 1.3974 - accuracy: 0.4641 - val_loss: 1.2651 - val_accuracy: 0.5126\n",
      "Epoch 12/50\n",
      "897/897 [==============================] - 48s 54ms/step - loss: 1.3779 - accuracy: 0.4731 - val_loss: 1.2389 - val_accuracy: 0.5294\n",
      "Epoch 13/50\n",
      "897/897 [==============================] - 48s 54ms/step - loss: 1.3737 - accuracy: 0.4734 - val_loss: 1.2330 - val_accuracy: 0.5269\n",
      "Epoch 14/50\n",
      "897/897 [==============================] - 48s 54ms/step - loss: 1.3726 - accuracy: 0.4732 - val_loss: 1.2804 - val_accuracy: 0.5204\n",
      "Epoch 15/50\n",
      "897/897 [==============================] - 48s 54ms/step - loss: 1.3602 - accuracy: 0.4801 - val_loss: 1.2582 - val_accuracy: 0.5273\n",
      "Epoch 16/50\n",
      "897/897 [==============================] - 49s 54ms/step - loss: 1.3528 - accuracy: 0.4812 - val_loss: 1.2185 - val_accuracy: 0.5399\n",
      "Epoch 17/50\n",
      "897/897 [==============================] - 49s 55ms/step - loss: 1.3542 - accuracy: 0.4837 - val_loss: 1.2468 - val_accuracy: 0.5292\n",
      "Epoch 18/50\n",
      "897/897 [==============================] - 49s 55ms/step - loss: 1.3426 - accuracy: 0.4876 - val_loss: 1.2573 - val_accuracy: 0.5329\n",
      "Epoch 19/50\n",
      "897/897 [==============================] - 52s 58ms/step - loss: 1.3343 - accuracy: 0.4912 - val_loss: 1.2082 - val_accuracy: 0.5374\n",
      "Epoch 20/50\n",
      "897/897 [==============================] - 83s 93ms/step - loss: 1.3284 - accuracy: 0.4907 - val_loss: 1.2131 - val_accuracy: 0.5398\n",
      "Epoch 21/50\n",
      "897/897 [==============================] - 57s 63ms/step - loss: 1.3244 - accuracy: 0.4917 - val_loss: 1.1966 - val_accuracy: 0.5352\n",
      "Epoch 22/50\n",
      "897/897 [==============================] - 59s 65ms/step - loss: 1.3259 - accuracy: 0.4892 - val_loss: 1.1888 - val_accuracy: 0.5453\n",
      "Epoch 23/50\n",
      "897/897 [==============================] - 52s 57ms/step - loss: 1.3239 - accuracy: 0.4970 - val_loss: 1.2255 - val_accuracy: 0.5321\n",
      "Epoch 24/50\n",
      "897/897 [==============================] - 48s 53ms/step - loss: 1.3129 - accuracy: 0.4987 - val_loss: 1.1863 - val_accuracy: 0.5516\n",
      "Epoch 25/50\n",
      "897/897 [==============================] - 48s 53ms/step - loss: 1.3071 - accuracy: 0.5042 - val_loss: 1.1931 - val_accuracy: 0.5490\n",
      "Epoch 26/50\n",
      "897/897 [==============================] - 47s 53ms/step - loss: 1.3009 - accuracy: 0.5012 - val_loss: 1.1847 - val_accuracy: 0.5512\n",
      "Epoch 27/50\n",
      "897/897 [==============================] - 48s 53ms/step - loss: 1.3028 - accuracy: 0.5024 - val_loss: 1.1828 - val_accuracy: 0.5476\n",
      "Epoch 28/50\n",
      "897/897 [==============================] - 48s 54ms/step - loss: 1.2957 - accuracy: 0.5052 - val_loss: 1.2007 - val_accuracy: 0.5502\n",
      "Epoch 29/50\n",
      "897/897 [==============================] - 48s 53ms/step - loss: 1.2956 - accuracy: 0.5036 - val_loss: 1.1848 - val_accuracy: 0.5530\n",
      "Epoch 30/50\n",
      "897/897 [==============================] - 48s 53ms/step - loss: 1.2868 - accuracy: 0.5097 - val_loss: 1.2008 - val_accuracy: 0.5448\n",
      "Epoch 31/50\n",
      "897/897 [==============================] - 47s 53ms/step - loss: 1.2804 - accuracy: 0.5147 - val_loss: 1.1645 - val_accuracy: 0.5598\n",
      "Epoch 32/50\n",
      "897/897 [==============================] - 48s 53ms/step - loss: 1.2829 - accuracy: 0.5108 - val_loss: 1.1977 - val_accuracy: 0.5480\n",
      "Epoch 33/50\n",
      "897/897 [==============================] - 48s 53ms/step - loss: 1.2755 - accuracy: 0.5131 - val_loss: 1.1628 - val_accuracy: 0.5565\n",
      "Epoch 34/50\n",
      "897/897 [==============================] - 48s 53ms/step - loss: 1.2760 - accuracy: 0.5136 - val_loss: 1.1659 - val_accuracy: 0.5597\n",
      "Epoch 35/50\n",
      "897/897 [==============================] - 52s 58ms/step - loss: 1.2675 - accuracy: 0.5149 - val_loss: 1.1669 - val_accuracy: 0.5566\n",
      "Epoch 36/50\n",
      "897/897 [==============================] - 48s 53ms/step - loss: 1.2698 - accuracy: 0.5132 - val_loss: 1.1569 - val_accuracy: 0.5589\n",
      "Epoch 37/50\n",
      "897/897 [==============================] - 58s 64ms/step - loss: 1.2740 - accuracy: 0.5145 - val_loss: 1.1587 - val_accuracy: 0.5605\n",
      "Epoch 38/50\n",
      "897/897 [==============================] - 56s 62ms/step - loss: 1.2704 - accuracy: 0.5182 - val_loss: 1.1495 - val_accuracy: 0.5640\n",
      "Epoch 39/50\n",
      "897/897 [==============================] - 53s 59ms/step - loss: 1.2621 - accuracy: 0.5170 - val_loss: 1.1481 - val_accuracy: 0.5658\n",
      "Epoch 40/50\n",
      "897/897 [==============================] - 47s 53ms/step - loss: 1.2599 - accuracy: 0.5202 - val_loss: 1.1509 - val_accuracy: 0.5610\n",
      "Epoch 41/50\n",
      "897/897 [==============================] - 47s 53ms/step - loss: 1.2579 - accuracy: 0.5189 - val_loss: 1.1480 - val_accuracy: 0.5626\n",
      "Epoch 42/50\n",
      "897/897 [==============================] - 52s 58ms/step - loss: 1.2584 - accuracy: 0.5177 - val_loss: 1.1598 - val_accuracy: 0.5647\n",
      "Epoch 43/50\n",
      "897/897 [==============================] - 51s 57ms/step - loss: 1.2507 - accuracy: 0.5229 - val_loss: 1.1483 - val_accuracy: 0.5640\n",
      "Epoch 44/50\n",
      "897/897 [==============================] - 48s 53ms/step - loss: 1.2578 - accuracy: 0.5165 - val_loss: 1.1480 - val_accuracy: 0.5633\n",
      "Epoch 45/50\n",
      "897/897 [==============================] - 47s 52ms/step - loss: 1.2504 - accuracy: 0.5262 - val_loss: 1.1806 - val_accuracy: 0.5488\n",
      "Epoch 46/50\n",
      "897/897 [==============================] - 47s 53ms/step - loss: 1.2502 - accuracy: 0.5248 - val_loss: 1.1575 - val_accuracy: 0.5612\n",
      "Epoch 47/50\n",
      "897/897 [==============================] - 48s 53ms/step - loss: 1.2362 - accuracy: 0.5250 - val_loss: 1.1434 - val_accuracy: 0.5672\n",
      "Epoch 48/50\n",
      "897/897 [==============================] - 48s 53ms/step - loss: 1.2441 - accuracy: 0.5270 - val_loss: 1.1532 - val_accuracy: 0.5625\n",
      "Epoch 49/50\n",
      "897/897 [==============================] - 48s 53ms/step - loss: 1.2366 - accuracy: 0.5297 - val_loss: 1.1420 - val_accuracy: 0.5619\n",
      "Epoch 50/50\n",
      "897/897 [==============================] - 47s 53ms/step - loss: 1.2438 - accuracy: 0.5247 - val_loss: 1.1590 - val_accuracy: 0.5586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d4416eb890>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "img_width, img_height = 48, 48  # dimensions to which the images will be resized\n",
    "batch_size = 32  # number of images per batch\n",
    "epochs = 50  # number of epochs to train for\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))  # Updated input shape\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))  # Removed groups parameter\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "train_data_dir = 'C:/Users/sides/Downloads/data/train'\n",
    "validation_data_dir = 'C:/Users/sides/Downloads/data/test'\n",
    "\n",
    "nb_train_samples = sum([len(files) for r, d, files in os.walk(train_data_dir)])\n",
    "nb_validation_samples = sum([len(files) for r, d, files in os.walk(validation_data_dir)])\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        color_mode='rgb')  # Specifying color mode as RGB\n",
    "                                                                    \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        color_mode='rgb')  # Specifying color mode as RGB\n",
    "\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sides\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# After training\n",
    "model.save('facial_expression_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "loaded_model = load_model('facial_expression_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step\n",
      "[[8.5411504e-02 1.0677345e-04 1.1229884e-01 3.5743147e-01 2.8809187e-01\n",
      "  1.3690968e-01 1.9749822e-02]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os \n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "loaded_model = load_model('facial_expression_model.h5')\n",
    "\n",
    "# Define a function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    img = image.load_img(image_path, target_size=(48, 48))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = img_array / 255.0  # Normalize pixel values\n",
    "    return img_array\n",
    "\n",
    "# Define a function to make predictions on the preprocessed image\n",
    "def predict_image(image_path, model):\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    prediction = model.predict(preprocessed_image)\n",
    "    return prediction\n",
    "\n",
    "# Test with a random image\n",
    "image_path = \"D:/SEM-6/NLP/Sticker/13.jpg\"\n",
    "prediction = predict_image(image_path, loaded_model)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "Predicted expression: Angry\n"
     ]
    }
   ],
   "source": [
    "# Define the labels\n",
    "labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\n",
    "\n",
    "# Test with a random image\n",
    "image_path = \"D:/SEM-6/NLP/Sticker/18.jpg\"\n",
    "prediction = predict_image(image_path, loaded_model)\n",
    "\n",
    "# Interpret the prediction\n",
    "predicted_label = labels[np.argmax(prediction)]\n",
    "print(\"Predicted expression:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
